{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 03 - Modélisation : Clustering RFM\n",
    "\n",
    "Ce notebook compare plusieurs algorithmes de clustering sur les features RFM scalées.\n",
    "\n",
    "**Étapes :**\n",
    "1. Chargement des données RFM scalées\n",
    "2. Recherche du K optimal (Elbow + Silhouette)\n",
    "3. K-means avec K choisi\n",
    "4. Comparaison : Hierarchical, DBSCAN\n",
    "5. Évaluation et stabilité\n",
    "6. Visualisation des clusters\n",
    "7. Sauvegarde du meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Modules projet\n",
    "from customer_segmentation.models.clustering import run_kmeans, run_hierarchical, run_dbscan\n",
    "from customer_segmentation.evaluation.metrics import compute_internal_metrics, stability_score\n",
    "from customer_segmentation.visualization.plots import plot_elbow, plot_silhouette, plot_clusters_2d\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins\n",
    "ROOT = Path.cwd()\n",
    "if not (ROOT / \"configs\" / \"params.yaml\").exists():\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "# Chargement configuration\n",
    "with open(ROOT / \"configs\" / \"params.yaml\", \"r\") as f:\n",
    "    params = yaml.safe_load(f)\n",
    "\n",
    "OUTPUT_DIR = ROOT / params[\"outputs\"][\"figures_dir\"]\n",
    "MODELS_DIR = ROOT / params[\"outputs\"][\"models_dir\"]\n",
    "\n",
    "print(f\"ROOT: {ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Chargement des données RFM scalées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement RFM scalé\n",
    "rfm_scaled = pd.read_csv(ROOT / \"data\" / \"features\" / \"rfm_scaled.csv\")\n",
    "rfm_raw = pd.read_csv(ROOT / \"data\" / \"features\" / \"rfm_raw.csv\")\n",
    "\n",
    "print(f\"Clients: {len(rfm_scaled):,}\")\n",
    "print(f\"Features: {list(rfm_scaled.columns)}\")\n",
    "rfm_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction matrice X pour clustering\n",
    "feature_cols = params[\"rfm\"][\"features\"]\n",
    "X = rfm_scaled[feature_cols].values\n",
    "\n",
    "print(f\"Shape X: {X.shape}\")\n",
    "print(f\"Features: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Recherche du K optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow + Silhouette\n",
    "k_range = range(2, 11)\n",
    "\n",
    "fig = plot_elbow(X, k_range=k_range, random_state=params[\"models\"][\"random_state\"])\n",
    "plt.savefig(OUTPUT_DIR / \"03_elbow_silhouette.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tableau détaillé des scores\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "results_k = []\n",
    "for k in k_range:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(X)\n",
    "    results_k.append({\n",
    "        \"K\": k,\n",
    "        \"Inertie\": km.inertia_,\n",
    "        \"Silhouette\": silhouette_score(X, labels),\n",
    "        \"Davies-Bouldin\": davies_bouldin_score(X, labels),\n",
    "        \"Calinski-Harabasz\": calinski_harabasz_score(X, labels)\n",
    "    })\n",
    "\n",
    "df_k = pd.DataFrame(results_k)\n",
    "df_k.style.highlight_max(subset=[\"Silhouette\", \"Calinski-Harabasz\"], color=\"lightgreen\") \\\n",
    "          .highlight_min(subset=[\"Davies-Bouldin\"], color=\"lightgreen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "**Analyse :**\n",
    "- **Silhouette** : Plus haut = meilleur (clusters bien séparés)\n",
    "- **Davies-Bouldin** : Plus bas = meilleur (clusters compacts)\n",
    "- **Calinski-Harabasz** : Plus haut = meilleur (variance inter/intra)\n",
    "\n",
    "Le coude de l'inertie et le maximum de silhouette suggèrent le K optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix du K basé sur silhouette max\n",
    "K_OPTIMAL = df_k.loc[df_k[\"Silhouette\"].idxmax(), \"K\"]\n",
    "print(f\"K optimal suggéré (max silhouette): {K_OPTIMAL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. K-means avec K optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means final\n",
    "labels_kmeans, model_kmeans = run_kmeans(\n",
    "    X, \n",
    "    n_clusters=int(K_OPTIMAL),\n",
    "    random_state=params[\"models\"][\"random_state\"],\n",
    "    n_init=params[\"models\"][\"kmeans\"][\"n_init\"]\n",
    ")\n",
    "\n",
    "# Métriques\n",
    "metrics_kmeans = compute_internal_metrics(X, labels_kmeans)\n",
    "print(f\"=== K-MEANS (K={int(K_OPTIMAL)}) ===\")\n",
    "for k, v in metrics_kmeans.items():\n",
    "    print(f\"  {k}: {v:.4f}\" if isinstance(v, float) else f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des clusters\n",
    "cluster_counts = pd.Series(labels_kmeans).value_counts().sort_index()\n",
    "print(\"Distribution des clusters:\")\n",
    "for cluster, count in cluster_counts.items():\n",
    "    print(f\"  Cluster {cluster}: {count:,} clients ({count/len(labels_kmeans)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagramme Silhouette\n",
    "fig = plot_silhouette(X, labels_kmeans)\n",
    "plt.savefig(OUTPUT_DIR / \"03_silhouette_kmeans.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation 2D des clusters\n",
    "fig = plot_clusters_2d(X, labels_kmeans, feature_names=feature_cols)\n",
    "plt.savefig(OUTPUT_DIR / \"03_clusters_2d_kmeans.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Comparaison : Hierarchical et DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical (même K)\n",
    "labels_hier, model_hier = run_hierarchical(\n",
    "    X, \n",
    "    n_clusters=int(K_OPTIMAL),\n",
    "    linkage=params[\"models\"][\"hierarchical\"][\"linkage\"]\n",
    ")\n",
    "metrics_hier = compute_internal_metrics(X, labels_hier)\n",
    "\n",
    "print(f\"=== HIERARCHICAL (K={int(K_OPTIMAL)}, linkage={params['models']['hierarchical']['linkage']}) ===\")\n",
    "for k, v in metrics_hier.items():\n",
    "    print(f\"  {k}: {v:.4f}\" if isinstance(v, float) else f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN - Grid search pour eps et min_samples\n",
    "print(\"=== DBSCAN GRID SEARCH ===\")\n",
    "\n",
    "dbscan_results = []\n",
    "for eps in params[\"models\"][\"dbscan\"][\"eps_range\"]:\n",
    "    for min_samples in params[\"models\"][\"dbscan\"][\"min_samples_range\"]:\n",
    "        labels_db, _ = run_dbscan(X, eps=eps, min_samples=min_samples)\n",
    "        n_clusters = len(set(labels_db)) - (1 if -1 in labels_db else 0)\n",
    "        noise_pct = (labels_db == -1).mean() * 100\n",
    "        \n",
    "        if n_clusters >= 2 and noise_pct < 50:  # Filtre résultats valides\n",
    "            metrics = compute_internal_metrics(X, labels_db)\n",
    "            dbscan_results.append({\n",
    "                \"eps\": eps,\n",
    "                \"min_samples\": min_samples,\n",
    "                \"n_clusters\": n_clusters,\n",
    "                \"noise_%\": noise_pct,\n",
    "                \"silhouette\": metrics[\"silhouette\"]\n",
    "            })\n",
    "\n",
    "if dbscan_results:\n",
    "    df_dbscan = pd.DataFrame(dbscan_results).sort_values(\"silhouette\", ascending=False)\n",
    "    display(df_dbscan.head(10))\n",
    "else:\n",
    "    print(\"Aucune configuration DBSCAN valide trouvée\")\n",
    "    df_dbscan = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meilleur DBSCAN\n",
    "if len(df_dbscan) > 0:\n",
    "    best_dbscan = df_dbscan.iloc[0]\n",
    "    labels_dbscan, model_dbscan = run_dbscan(\n",
    "        X, \n",
    "        eps=best_dbscan[\"eps\"], \n",
    "        min_samples=int(best_dbscan[\"min_samples\"])\n",
    "    )\n",
    "    metrics_dbscan = compute_internal_metrics(X, labels_dbscan)\n",
    "    \n",
    "    print(f\"=== MEILLEUR DBSCAN (eps={best_dbscan['eps']}, min_samples={int(best_dbscan['min_samples'])}) ===\")\n",
    "    for k, v in metrics_dbscan.items():\n",
    "        print(f\"  {k}: {v:.4f}\" if isinstance(v, float) else f\"  {k}: {v}\")\n",
    "else:\n",
    "    labels_dbscan = None\n",
    "    metrics_dbscan = {\"silhouette\": np.nan, \"davies_bouldin\": np.nan, \"calinski_harabasz\": np.nan}\n",
    "    print(\"DBSCAN non applicable sur ces données\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Comparaison finale des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tableau comparatif\n",
    "comparison = pd.DataFrame({\n",
    "    \"Modèle\": [\"K-Means\", \"Hierarchical\", \"DBSCAN\"],\n",
    "    \"K / Clusters\": [int(K_OPTIMAL), int(K_OPTIMAL), metrics_dbscan.get(\"n_clusters\", \"N/A\")],\n",
    "    \"Silhouette\": [metrics_kmeans[\"silhouette\"], metrics_hier[\"silhouette\"], metrics_dbscan.get(\"silhouette\", np.nan)],\n",
    "    \"Davies-Bouldin\": [metrics_kmeans[\"davies_bouldin\"], metrics_hier[\"davies_bouldin\"], metrics_dbscan.get(\"davies_bouldin\", np.nan)],\n",
    "    \"Calinski-Harabasz\": [metrics_kmeans[\"calinski_harabasz\"], metrics_hier[\"calinski_harabasz\"], metrics_dbscan.get(\"calinski_harabasz\", np.nan)]\n",
    "})\n",
    "\n",
    "comparison.style.highlight_max(subset=[\"Silhouette\", \"Calinski-Harabasz\"], color=\"lightgreen\") \\\n",
    "               .highlight_min(subset=[\"Davies-Bouldin\"], color=\"lightgreen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection du meilleur modèle (basé sur silhouette)\n",
    "best_idx = comparison[\"Silhouette\"].idxmax()\n",
    "best_model_name = comparison.loc[best_idx, \"Modèle\"]\n",
    "\n",
    "print(f\"\\n=== MEILLEUR MODÈLE: {best_model_name} ===\")\n",
    "print(comparison.loc[best_idx].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Stabilité du clustering (Bootstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stabilité K-means\n",
    "def kmeans_func(X_sample):\n",
    "    km = KMeans(n_clusters=int(K_OPTIMAL), random_state=42, n_init=10)\n",
    "    return km.fit_predict(X_sample)\n",
    "\n",
    "stability = stability_score(\n",
    "    X, \n",
    "    kmeans_func, \n",
    "    n_bootstrap=params[\"evaluation\"][\"n_bootstrap\"],\n",
    "    sample_ratio=params[\"evaluation\"][\"bootstrap_ratio\"]\n",
    ")\n",
    "\n",
    "print(f\"Stabilité K-means (ARI moyen): {stability:.4f}\")\n",
    "print(f\"  > 0.8 = stable, 0.6-0.8 = modéré, < 0.6 = instable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Sauvegarde du modèle et des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout des labels au dataframe RFM\n",
    "rfm_with_clusters = rfm_raw.copy()\n",
    "rfm_with_clusters[\"Cluster\"] = labels_kmeans\n",
    "\n",
    "# Sauvegarde\n",
    "rfm_with_clusters.to_csv(ROOT / \"data\" / \"features\" / \"rfm_clustered.csv\", index=False)\n",
    "joblib.dump(model_kmeans, MODELS_DIR / \"kmeans_model.joblib\")\n",
    "\n",
    "# Sauvegarde comparaison\n",
    "comparison.to_csv(ROOT / \"outputs\" / \"reports\" / \"model_comparison.csv\", index=False)\n",
    "\n",
    "print(\"=== SAUVEGARDE TERMINÉE ===\")\n",
    "print(f\"✓ RFM avec clusters: data/features/rfm_clustered.csv\")\n",
    "print(f\"✓ Modèle K-means: outputs/models/kmeans_model.joblib\")\n",
    "print(f\"✓ Comparaison: outputs/reports/model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aperçu final\n",
    "print(\"\\n=== PROFIL DES CLUSTERS (valeurs brutes) ===\")\n",
    "cluster_profile = rfm_with_clusters.groupby(\"Cluster\")[[\"Recency\", \"Frequency\", \"Monetary\"]].agg([\"mean\", \"median\", \"count\"])\n",
    "cluster_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "---\n",
    "## Résumé\n",
    "\n",
    "| Élément | Valeur |\n",
    "|---------|--------|\n",
    "| Algorithme retenu | K-Means |\n",
    "| Nombre de clusters | K optimal |\n",
    "| Score Silhouette | (voir ci-dessus) |\n",
    "| Stabilité (ARI) | (voir ci-dessus) |\n",
    "\n",
    "**Artefacts générés :**\n",
    "- `data/features/rfm_clustered.csv`\n",
    "- `outputs/models/kmeans_model.joblib`\n",
    "- `outputs/reports/model_comparison.csv`\n",
    "- Figures dans `outputs/figures/`\n",
    "\n",
    "→ **Prochaine étape** : Notebook 04_interpretation.ipynb (profils segments, nommage business, recommandations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
